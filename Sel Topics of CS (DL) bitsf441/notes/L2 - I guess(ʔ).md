---
attachments: [Clipboard_2020-08-25-11-38-16.png]
title: L2 - I guess(?)
created: '2020-08-25T05:35:34.970Z'
modified: '2020-08-25T06:24:57.268Z'
---

# L2 - I guess(?)
 - Deep learning can help discern / disentangle the accent from the voice and get just the pronunciation, through having layers for representing the accent

- Three historical waves
  - Cybernetics (1970s)
  - Connectionism/ Neural networks (peaked in 1995)
  - Deep learning  (2006+, layerwise training, big data)

- Hardware didn't increase immensely until 2015, so that's why they were able to increase suddenly only then
  - so we will need a immense development in hardware for a machine to reach the number of neurons in humans. And even then it may not think just as well. 
  - DL is *not* simulating a brain. It is inspired from the brain, not immitation

![](@attachment/Clipboard_2020-08-25-11-38-16.png)

- number of connections per neuron for a  human is 10^4, and we have reached that  in a COTS HPC unsupervised CNN, but most of our models are still nowhere in comparison. Perhaps we don't even want to simulate the brain. 


## One learning algorithm Hypothesis
  - Most perception (input processing) in the brain may be due to one learning algorithm
    so even if the vision cortex is damaged, the auditory cortex is forced to learn and can make up for it
    

